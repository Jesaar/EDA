{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "x_9rIZKCfxz8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "executionInfo": {
     "elapsed": 60308,
     "status": "ok",
     "timestamp": 1762606086210,
     "user": {
      "displayName": "Juan Betancur",
      "userId": "03799181972231353223"
     },
     "user_tz": 300
    },
    "id": "kAmym2rigBxl",
    "outputId": "cd139e73-8a34-4587-8800-9b3592a55171"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mEl kernel se bloqueó al ejecutar código en la celda actual o en una celda anterior. \n",
      "\u001b[1;31mRevise el código de las celdas para identificar una posible causa del error. \n",
      "\u001b[1;31mHaga clic <a href='https://aka.ms/vscodeJupyterKernelCrash'>aquí</a> para obtener más información. \n",
      "\u001b[1;31mVea Jupyter <a href='command:jupyter.viewOutput'>log</a> para obtener más detalles."
     ]
    }
   ],
   "source": [
    "path_clean_df = \"clean_amazon_review_full.parquet\"\n",
    "df = pd.read_parquet(path_clean_df, engine=\"pyarrow\")\n",
    "df.head()\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de núcleos de CPU disponibles: 16\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "num_cpus = os.cpu_count()\n",
    "print(f\"Cantidad de núcleos de CPU disponibles: {num_cpus}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1762607199001,
     "user": {
      "displayName": "Juan Betancur",
      "userId": "03799181972231353223"
     },
     "user_tz": 300
    },
    "id": "jfWYV8ccjTu7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import langid\n",
    "from multiprocessing import Pool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PzSCep39kiGP",
    "outputId": "d14b881e-8bb2-4bf2-e918-9a5912687310"
   },
   "outputs": [],
   "source": [
    "OUTPUT_PARQUET = \"/content/drive/MyDrive/00. Universidad/02. Analisis de Datos/evento evaluativo 4/amazon_review_full_csv/classified_language_amazon_sentiment.parquet\"\n",
    "BATCH_SIZE = 10_000         # tamaño del batch; ajusta si falta RAM o quieres más granuralidad\n",
    "MAX_WORKERS = max(1, min(os.cpu_count() - 1 or 1, 8))  # número de procesos; ajustar (no más de 8 recomendado usualmente)\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "# Opcional: limitar idiomas conocidos (si quieres aumentar rapidez)\n",
    "# langid.set_languages(['es','en','pt','fr','de','it','nl'])  # descomenta y personaliza si sabes qué idiomas dominan\n",
    "\n",
    "def process_batch(texts):\n",
    "    \"\"\"\n",
    "    Función que recibe una lista de strings y devuelve lista de tuplas (lang, score)\n",
    "    Debe estar en el scope global para que multiprocessing la pueda serializar.\n",
    "    \"\"\"\n",
    "    # nota: langid.classify devuelve tupla (idioma, score) donde score es log-probabilidad (más alto = más seguro)\n",
    "    out = [langid.classify(t) for t in texts]\n",
    "    return out\n",
    "\n",
    "def batch_generator(iterable, batch_size):\n",
    "    \"\"\"Generador que itera en lotes preservando orden\"\"\"\n",
    "    for i in range(0, len(iterable), batch_size):\n",
    "        yield iterable[i:i + batch_size]\n",
    "\n",
    "# ----------------------- flujo principal --------------------------------\n",
    "print(\"Leyendo parquet en memoria...\")\n",
    "\n",
    "# Normalizar la columna a strings y rellenar nans\n",
    "texts = df['clean_title'].fillna('').astype(str).tolist()\n",
    "n = len(texts)\n",
    "n_batches = math.ceil(n / BATCH_SIZE)\n",
    "print(f\"Tamaño dataset: {n} registros -> {n_batches} batches de ~{BATCH_SIZE}\")\n",
    "\n",
    "# Preparar listas donde iremos agregando resultados (en orden)\n",
    "languages = [None] * n\n",
    "confidences = [None] * n\n",
    "\n",
    "# Procesar por batches usando Pool.imap para mantener el orden\n",
    "batches = list(batch_generator(texts, BATCH_SIZE))\n",
    "\n",
    "print(f\"Iniciando multiprocessing con {MAX_WORKERS} workers...\")\n",
    "with Pool(processes=MAX_WORKERS) as pool:\n",
    "    # pool.imap mantiene el orden de los batches\n",
    "    for batch_idx, batch_result in enumerate(tqdm(pool.imap(process_batch, batches), total=n_batches)):\n",
    "        start = batch_idx * BATCH_SIZE\n",
    "        # batch_result es lista de tuplas con la misma longitud del batch\n",
    "        for j, (lang, score) in enumerate(batch_result):\n",
    "            idx = start + j\n",
    "            # Evitar overflow si el último batch es más corto\n",
    "            if idx < n:\n",
    "                languages[idx] = lang\n",
    "                confidences[idx] = score\n",
    "\n",
    "# Asignar resultados al dataframe (misma longitud y orden que texts original)\n",
    "df['lang_detected'] = languages\n",
    "df['lang_confidence'] = confidences\n",
    "\n",
    "# Guardar resultado\n",
    "df.to_parquet(OUTPUT_PARQUET , index=False)\n",
    "print(\"Hecho. Resultado guardado en:\", OUTPUT_PARQUET)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyON46YYyLL2RpHQwuHAVsSE",
   "mount_file_id": "156XzwyITBCM5XoXOAdmgyyUw-MU_sfxP",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "EDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
